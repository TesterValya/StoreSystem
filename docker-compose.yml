version: "3.9"

services:
  # Kafka - брокер сообщений
  kafka:
    image: apache/kafka:3.8.0
    container_name: kafka
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_CLUSTER_ID: "5L6g3nShT-eMCtK--X86sw" # Cluster ID из логов
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
    ports:
      - "9092:9092"
      - "9093:9093"
    volumes:
      - /var/lib/kafka/data
    networks:
      - app_network
    healthcheck:
      test: [ "CMD-SHELL", "/opt/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server kafka:9092 || exit 1" ]
      interval: 5s
      timeout: 5s
      retries: 5

  topic_creator:
    image: apache/kafka:3.8.0
    depends_on:
      kafka:
        condition: service_healthy
    command: >
      sh -c "/opt/kafka/bin/kafka-topics.sh --create --topic __consumer_offsets --partitions 50 --replication-factor 1 --bootstrap-server kafka:9092; "
    networks:
      - app_network

  # Elasticsearch - хранилище логов
  elasticsearch:
    image: elasticsearch:7.17.18
    container_name: elasticsearch
    environment:
      - bootstrap.memory_lock=true
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - 9200:9200
    stdin_open: true
    tty: true
    networks:
      - app_network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "50"

  # Logstash - обработка и отправка логов в Elasticsearch
  logstash:
    container_name: logstash
    image: logstash:7.17.18
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - ./logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf
      - ./logstash/logstash.template.json:/usr/share/logstash/templates/logstash.template.json
    ports:
      - 5044:5044
    links:
      - elasticsearch:elasticsearch
    depends_on:
      - elasticsearch
    stdin_open: true
    tty: true
    networks:
      - app_network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "50"

  # Kibana - интерфейс для просмотра логов
  kibana:
    container_name: kibana
    image: kibana:7.17.18
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - 5601:5601
    links:
      - elasticsearch:elasticsearch
    depends_on:
      - elasticsearch
    stdin_open: true
    tty: true
    networks:
      - app_network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "50"

  # Filebeat - сборщик логов с контейнеров
  filebeat:
    user: root
    container_name: filebeat
    image: elastic/filebeat:7.17.18
    links:
      - logstash:logstash
    depends_on:
      - logstash
      - auth_service
      - products_service
    volumes:
      - /var/run/docker.sock:/host_docker/docker.sock
      - ./auth_service/logs:/usr/share/filebeat/auth_service
      - ./products_service/logs:/usr/share/filebeat/products_service
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml
    command: [ "--strict.perms=false" ]
    ulimits:
      memlock:
        soft: -1
        hard: -1
    stdin_open: true
    tty: true
    networks:
      - app_network
    deploy:
      mode: global
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "50"

  db_auth:
    image: postgres:12-bullseye
    container_name: postgres_auth_db
    environment:
      POSTGRES_USER: storage_admin # Задать пользователя
      POSTGRES_PASSWORD: THw7l0bxvPPkWUhP # Задать пароль
      POSTGRES_DB: strg_users_db # Задать имя БД
    ports:
      - "5435:5432" # Открыть порт для внешнего доступа
    volumes:
      - ./docker-data/auth_db:/var/lib/postgresql/data
      - ./auth_service/db_init/init.sql:/docker-entrypoint-initdb.d/init.sql # Путь к папке с SQL-скриптами
    networks:
      - app_network

  db_products:
    image: postgres:12-bullseye
    container_name: postgres_products_db
    environment:
      POSTGRES_USER: storage_admin # Задать пользователя
      POSTGRES_PASSWORD: THw7l0bxvPPkWUhP # Задать пароль
      POSTGRES_DB: strg_products_db # Задать имя БД
    ports:
      - "5436:5432" # Открыть порт для внешнего доступа
    volumes:
      - ./docker-data/products_db:/var/lib/postgresql/data
      - ./products_service/db_init/init_products.sql:/docker-entrypoint-initdb.d/init.sql # Путь к папке с SQL-скриптами
    networks:
      - app_network

  auth_service:
    build:
      context: ./auth_service
      dockerfile: Dockerfile
    container_name: auth_service
    volumes:
      - ./auth_service/logs:/app/logs
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      DATABASE_URL: postgresql://storage_admin:THw7l0bxvPPkWUhP@db:5432/strg_users_db
    ports:
      - "8001:8000" # Открыть порт для FastAPI или другого веб-сервиса
    networks:
      - app_network

  products_service:
    build:
      context: ./products_service
      dockerfile: Dockerfile
    container_name: products_service
    volumes:
      - ./products_service/logs:/app/logs
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      DATABASE_URL: postgresql://storage_admin:THw7l0bxvPPkWUhP@db_products:5432/strg_products_db
    ports:
      - "8002:8000" # Открываем порт для сервиса продуктов
    networks:
      - app_network

networks:
  app_network:
    driver: bridge
